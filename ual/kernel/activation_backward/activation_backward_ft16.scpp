// BSD 3- Clause License Copyright (c) 2024, Tecorigin Co., Ltd. All rights
// reserved.
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are met:
// Redistributions of source code must retain the above copyright notice,
// this list of conditions and the following disclaimer.
// Redistributions in binary form must reproduce the above copyright notice,
// this list of conditions and the following disclaimer in the documentation
// and/or other materials provided with the distribution.
// Neither the name of the copyright holder nor the names of its contributors
// may be used to endorse or promote products derived from this software
// without specific prior written permission.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
// ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
// LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
// CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
// SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
// INTERRUPTION)
// HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
// STRICT LIABILITY,OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)  ARISING IN ANY
// WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY
// OF SUCH DAMAGE.

#include "ual/kernel/activation_backward/activation_backward.h"
#include "ual/com/dma_all_type.h"

using namespace sdaa;
using namespace tecoal::ual::common;

namespace tecoal {
namespace ual {
namespace kernel {

#define CDBUF(x) (buf_dbflag == 0 ? x##0 : x##1)
#define ADBUF(x) (buf_dbflag == 0 ? x##1 : x##0)
#define EXDBF buf_dbflag = 1 - buf_dbflag

// v1: fabs(beta) <= 1e-5 && fabs(alpha - 1.0f) <= 1e-5
__device__ static void backwardSiluV1(half *dx, half *dy, half *x, half *buf, int num, float alpha,
                                      float beta);
// v2: if (fabs(alpha - 1.0f) > 1e-5)
__device__ static void backwardSiluV2(half *dx, half *dy, half *x, half *buf, int num, float alpha,
                                      float beta);
// v3: if (fabs(beta) > 1e-5)
__device__ static void backwardSiluV3(half *dx, half *dy, half *x, half *buf, int num, float alpha,
                                      float beta);
// v4: fabs(beta) > 1e-5 && fabs(alpha - 1.0f) > 1e-5
__device__ static void backwardSiluV4(half *dx, half *dy, half *x, half *buf, int num, float alpha,
                                      float beta);

__device__ static void backwardSilu(half *dx, half *dy, half *x, half *buf, int num, float alpha,
                                    float beta) {
    if (fabs(beta) > 1e-5 && fabs(alpha - 1.0f) > 1e-5) {
        backwardSiluV4(dx, dy, x, buf, num, alpha, beta);
    } else if (fabs(beta) > 1e-5) {
        backwardSiluV3(dx, dy, x, buf, num, alpha, beta);
    } else if (fabs(alpha - 1.0f) > 1e-5) {
        backwardSiluV2(dx, dy, x, buf, num, alpha, beta);
    } else {
        backwardSiluV1(dx, dy, x, buf, num, alpha, beta);
    }
}

__global__ void tecoKernelActivationBackwardSiluFT16(ActivationBwdArgs abarg) {
    const int data_num = abarg.data_num;
    const int spe_num = abarg.spe_num;
    const double coef = abarg.COEF;
    const float alpha = abarg.alpha;
    const float beta = abarg.beta;
    half *x = (half *)abarg.x;
    half *y = (half *)abarg.y;
    half *dy = (half *)abarg.dy;
    half *dx = (half *)abarg.dx;

    const int tid = threadIdx;
    int BlockSize = 16 * 1024;
    int num_per_loop = BlockSize / sizeof(half);

    int i = tid * num_per_loop;
    if (i >= data_num) return;

    // x, y, dx, dy
    half *xbuf0 = (half *)malloc(BlockSize);
    half *xbuf1 = (half *)malloc(BlockSize);
    half *dxbuf0 = (half *)malloc(BlockSize);
    half *dxbuf1 = (half *)malloc(BlockSize);
    half *dybuf0 = (half *)malloc(BlockSize);
    half *dybuf1 = (half *)malloc(BlockSize);
    half *buf = (half *)malloc(BlockSize);

    int buf_dbflag = 0;
    MemcpyHandle get_handle[2];
    MemcpyHandle put_handle[2];

    const int num_all_spe = num_per_loop * spe_num;
    int cur_num, next_num, next_i, flag_next, ii;
    int flag_beta = (fabs(beta) > 1e-5);
    int wait_get_value = flag_beta ? 3 : 2;

    cur_num = MIN(num_per_loop, data_num - i);
    allDmaIgetTwoByteAlignedSdaa(CDBUF(xbuf), x + i, cur_num * sizeof(half),
                                 get_handle[buf_dbflag]);
    allDmaIgetTwoByteAlignedSdaa(CDBUF(dybuf), dy + i, cur_num * sizeof(half),
                                 get_handle[buf_dbflag]);
    if (flag_beta)
        allDmaIgetTwoByteAlignedSdaa(CDBUF(dxbuf), dx + i, cur_num * sizeof(half),
                                     get_handle[buf_dbflag]);

    for (; i < data_num; i += num_all_spe) {
        next_i = i + num_all_spe;
        flag_next = next_i < data_num;

        if (flag_next) {
            next_num = MIN(num_per_loop, data_num - next_i);
            allDmaIgetTwoByteAlignedSdaa(ADBUF(xbuf), x + next_i, next_num * sizeof(half),
                                         get_handle[1 - buf_dbflag]);
            allDmaIgetTwoByteAlignedSdaa(ADBUF(dybuf), dy + next_i, next_num * sizeof(half),
                                         get_handle[1 - buf_dbflag]);
            if (flag_beta)
                allDmaIgetTwoByteAlignedSdaa(ADBUF(dxbuf), dx + next_i, next_num * sizeof(half),
                                             get_handle[1 - buf_dbflag]);
        }

        memcpy_wait(get_handle[buf_dbflag]);
        memcpy_wait(put_handle[buf_dbflag]);

        backwardSilu(CDBUF(dxbuf), CDBUF(dybuf), CDBUF(xbuf), buf, cur_num, alpha, beta);

        allDmaIputTwoByteAlignedSdaa(dx + i, CDBUF(dxbuf), cur_num * sizeof(half),
                                     put_handle[buf_dbflag]);

        if (flag_next) {
            EXDBF;
            cur_num = next_num;
        }
    }

    memcpy_wait(put_handle[buf_dbflag]);
    memcpy_wait(put_handle[1 - buf_dbflag]);

    free(xbuf0);
    free(xbuf1);
    free(dxbuf0);
    free(dxbuf1);
    free(dybuf0);
    free(dybuf1);
    free(buf);
}

// v1: fabs(beta) <= 1e-5 && fabs(alpha - 1.0f) <= 1e-5
__device__ static void backwardSiluV1(half *dx, half *dy, half *x, half *buf, int num, float alpha,
                                      float beta) {
    float A[128] __attribute__((aligned(64)));
    floatv16 v1 = 1.0f;
    float16v16 vh0, vh1, vh2, vh3, vh4, vh5, vh6, vh7;
    floatv16 vf_dy_0, vf_dy_1, vf_dy_2, vf_dy_3, vf_dy_4, vf_dy_5, vf_dy_6, vf_dy_7;
    floatv16 vf_sg_0, vf_sg_1, vf_sg_2, vf_sg_3, vf_sg_4, vf_sg_5, vf_sg_6, vf_sg_7;
    floatv16 vf_x_0, vf_x_1, vf_x_2, vf_x_3, vf_x_4, vf_x_5, vf_x_6, vf_x_7;
    for (int i = 0; i < num; i += 128) {
        simd_load(vh0, x + i);
        simd_load(vh1, x + i + 16);
        simd_load(vh2, x + i + 32);
        simd_load(vh3, x + i + 48);
        simd_load(vh4, x + i + 64);
        simd_load(vh5, x + i + 80);
        simd_load(vh6, x + i + 96);
        simd_load(vh7, x + i + 112);

        vf_x_0 = vh0;
        vf_x_1 = vh1;
        vf_x_2 = vh2;
        vf_x_3 = vh3;
        vf_x_4 = vh4;
        vf_x_5 = vh5;
        vf_x_6 = vh6;
        vf_x_7 = vh7;

        simd_store(vf_x_0, A);
        simd_store(vf_x_1, A + 16);
        simd_store(vf_x_2, A + 32);
        simd_store(vf_x_3, A + 48);
        simd_store(vf_x_4, A + 64);
        simd_store(vf_x_5, A + 80);
        simd_store(vf_x_6, A + 96);
        simd_store(vf_x_7, A + 112);

        simd_load(vh0, dy + i);
        simd_load(vh1, dy + i + 16);
        simd_load(vh2, dy + i + 32);
        simd_load(vh3, dy + i + 48);
        simd_load(vh4, dy + i + 64);
        simd_load(vh5, dy + i + 80);
        simd_load(vh6, dy + i + 96);
        simd_load(vh7, dy + i + 112);

        simd_sigmoid128(A);  // sigmoid(x)

        vf_dy_0 = vh0;
        vf_dy_1 = vh1;
        vf_dy_2 = vh2;
        vf_dy_3 = vh3;
        vf_dy_4 = vh4;
        vf_dy_5 = vh5;
        vf_dy_6 = vh6;
        vf_dy_7 = vh7;

        simd_load(vf_sg_0, A);
        simd_load(vf_sg_1, A + 16);
        simd_load(vf_sg_2, A + 32);
        simd_load(vf_sg_3, A + 48);
        simd_load(vf_sg_4, A + 64);
        simd_load(vf_sg_5, A + 80);
        simd_load(vf_sg_6, A + 96);
        simd_load(vf_sg_7, A + 112);

        vf_dy_0 = vf_dy_0 * vf_sg_0;
        vf_dy_1 = vf_dy_1 * vf_sg_1;
        vf_dy_2 = vf_dy_2 * vf_sg_2;
        vf_dy_3 = vf_dy_3 * vf_sg_3;
        vf_dy_4 = vf_dy_4 * vf_sg_4;
        vf_dy_5 = vf_dy_5 * vf_sg_5;
        vf_dy_6 = vf_dy_6 * vf_sg_6;
        vf_dy_7 = vf_dy_7 * vf_sg_7;

        vf_sg_0 = v1 - vf_sg_0;
        vf_sg_1 = v1 - vf_sg_1;
        vf_sg_2 = v1 - vf_sg_2;
        vf_sg_3 = v1 - vf_sg_3;
        vf_sg_4 = v1 - vf_sg_4;
        vf_sg_5 = v1 - vf_sg_5;
        vf_sg_6 = v1 - vf_sg_6;
        vf_sg_7 = v1 - vf_sg_7;

        vf_x_0 *= vf_sg_0;
        vf_x_1 *= vf_sg_1;
        vf_x_2 *= vf_sg_2;
        vf_x_3 *= vf_sg_3;
        vf_x_4 *= vf_sg_4;
        vf_x_5 *= vf_sg_5;
        vf_x_6 *= vf_sg_6;
        vf_x_7 *= vf_sg_7;

        vf_x_0 += v1;
        vf_x_1 += v1;
        vf_x_2 += v1;
        vf_x_3 += v1;
        vf_x_4 += v1;
        vf_x_5 += v1;
        vf_x_6 += v1;
        vf_x_7 += v1;

        vf_dy_0 = vf_dy_0 * vf_x_0;
        vf_dy_1 = vf_dy_1 * vf_x_1;
        vf_dy_2 = vf_dy_2 * vf_x_2;
        vf_dy_3 = vf_dy_3 * vf_x_3;
        vf_dy_4 = vf_dy_4 * vf_x_4;
        vf_dy_5 = vf_dy_5 * vf_x_5;
        vf_dy_6 = vf_dy_6 * vf_x_6;
        vf_dy_7 = vf_dy_7 * vf_x_7;

        vh0 = vf_dy_0;
        vh1 = vf_dy_1;
        vh2 = vf_dy_2;
        vh3 = vf_dy_3;
        vh4 = vf_dy_4;
        vh5 = vf_dy_5;
        vh6 = vf_dy_6;
        vh7 = vf_dy_7;

        simd_store(vh0, dx + i);
        simd_store(vh1, dx + i + 16);
        simd_store(vh2, dx + i + 32);
        simd_store(vh3, dx + i + 48);
        simd_store(vh4, dx + i + 64);
        simd_store(vh5, dx + i + 80);
        simd_store(vh6, dx + i + 96);
        simd_store(vh7, dx + i + 112);
    }
}

// v4: fabs(beta) > 1e-5 && fabs(alpha - 1.0f) > 1e-5
__device__ static void backwardSiluV4(half *dx, half *dy, half *x, half *buf, int num, float alpha,
                                      float beta) {
    float A[128] __attribute__((aligned(64)));
    floatv16 v1 = 1.0f;
    floatv16 valpha = alpha;
    floatv16 vbeta = beta;
    float16v16 vh0, vh1, vh2, vh3, vh4, vh5, vh6, vh7;
    floatv16 vf_dy_0, vf_dy_1, vf_dy_2, vf_dy_3, vf_dy_4, vf_dy_5, vf_dy_6, vf_dy_7;
    floatv16 vf_sg_0, vf_sg_1, vf_sg_2, vf_sg_3, vf_sg_4, vf_sg_5, vf_sg_6, vf_sg_7;
    floatv16 vf_x_0, vf_x_1, vf_x_2, vf_x_3, vf_x_4, vf_x_5, vf_x_6, vf_x_7;
    for (int i = 0; i < num; i += 128) {
        simd_load(vh0, x + i);
        simd_load(vh1, x + i + 16);
        simd_load(vh2, x + i + 32);
        simd_load(vh3, x + i + 48);
        simd_load(vh4, x + i + 64);
        simd_load(vh5, x + i + 80);
        simd_load(vh6, x + i + 96);
        simd_load(vh7, x + i + 112);

        vf_x_0 = vh0;
        vf_x_1 = vh1;
        vf_x_2 = vh2;
        vf_x_3 = vh3;
        vf_x_4 = vh4;
        vf_x_5 = vh5;
        vf_x_6 = vh6;
        vf_x_7 = vh7;

        simd_store(vf_x_0, A);
        simd_store(vf_x_1, A + 16);
        simd_store(vf_x_2, A + 32);
        simd_store(vf_x_3, A + 48);
        simd_store(vf_x_4, A + 64);
        simd_store(vf_x_5, A + 80);
        simd_store(vf_x_6, A + 96);
        simd_store(vf_x_7, A + 112);

        simd_load(vh0, dy + i);
        simd_load(vh1, dy + i + 16);
        simd_load(vh2, dy + i + 32);
        simd_load(vh3, dy + i + 48);
        simd_load(vh4, dy + i + 64);
        simd_load(vh5, dy + i + 80);
        simd_load(vh6, dy + i + 96);
        simd_load(vh7, dy + i + 112);

        simd_sigmoid128(A);  // sigmoid(x)

        vf_dy_0 = vh0;
        vf_dy_1 = vh1;
        vf_dy_2 = vh2;
        vf_dy_3 = vh3;
        vf_dy_4 = vh4;
        vf_dy_5 = vh5;
        vf_dy_6 = vh6;
        vf_dy_7 = vh7;

        simd_load(vf_sg_0, A);
        simd_load(vf_sg_1, A + 16);
        simd_load(vf_sg_2, A + 32);
        simd_load(vf_sg_3, A + 48);
        simd_load(vf_sg_4, A + 64);
        simd_load(vf_sg_5, A + 80);
        simd_load(vf_sg_6, A + 96);
        simd_load(vf_sg_7, A + 112);

        vf_dy_0 = vf_dy_0 * vf_sg_0;
        vf_dy_1 = vf_dy_1 * vf_sg_1;
        vf_dy_2 = vf_dy_2 * vf_sg_2;
        vf_dy_3 = vf_dy_3 * vf_sg_3;
        vf_dy_4 = vf_dy_4 * vf_sg_4;
        vf_dy_5 = vf_dy_5 * vf_sg_5;
        vf_dy_6 = vf_dy_6 * vf_sg_6;
        vf_dy_7 = vf_dy_7 * vf_sg_7;

        vf_sg_0 = v1 - vf_sg_0;
        vf_sg_1 = v1 - vf_sg_1;
        vf_sg_2 = v1 - vf_sg_2;
        vf_sg_3 = v1 - vf_sg_3;
        vf_sg_4 = v1 - vf_sg_4;
        vf_sg_5 = v1 - vf_sg_5;
        vf_sg_6 = v1 - vf_sg_6;
        vf_sg_7 = v1 - vf_sg_7;

        vf_x_0 *= vf_sg_0;
        vf_x_1 *= vf_sg_1;
        vf_x_2 *= vf_sg_2;
        vf_x_3 *= vf_sg_3;
        vf_x_4 *= vf_sg_4;
        vf_x_5 *= vf_sg_5;
        vf_x_6 *= vf_sg_6;
        vf_x_7 *= vf_sg_7;

        vf_x_0 += v1;
        vf_x_1 += v1;
        vf_x_2 += v1;
        vf_x_3 += v1;
        vf_x_4 += v1;
        vf_x_5 += v1;
        vf_x_6 += v1;
        vf_x_7 += v1;

        vf_dy_0 = vf_dy_0 * vf_x_0;
        vf_dy_1 = vf_dy_1 * vf_x_1;
        vf_dy_2 = vf_dy_2 * vf_x_2;
        vf_dy_3 = vf_dy_3 * vf_x_3;
        vf_dy_4 = vf_dy_4 * vf_x_4;
        vf_dy_5 = vf_dy_5 * vf_x_5;
        vf_dy_6 = vf_dy_6 * vf_x_6;
        vf_dy_7 = vf_dy_7 * vf_x_7;

        // if (fabs(alpha - 1.0f) > 1e-5)
        vf_dy_0 = vf_dy_0 * valpha;
        vf_dy_1 = vf_dy_1 * valpha;
        vf_dy_2 = vf_dy_2 * valpha;
        vf_dy_3 = vf_dy_3 * valpha;
        vf_dy_4 = vf_dy_4 * valpha;
        vf_dy_5 = vf_dy_5 * valpha;
        vf_dy_6 = vf_dy_6 * valpha;
        vf_dy_7 = vf_dy_7 * valpha;

        simd_load(vh0, dx + i);
        simd_load(vh1, dx + i + 16);
        simd_load(vh2, dx + i + 32);
        simd_load(vh3, dx + i + 48);
        simd_load(vh4, dx + i + 64);
        simd_load(vh5, dx + i + 80);
        simd_load(vh6, dx + i + 96);
        simd_load(vh7, dx + i + 112);

        vf_x_0 = vh0;
        vf_x_1 = vh1;
        vf_x_2 = vh2;
        vf_x_3 = vh3;
        vf_x_4 = vh4;
        vf_x_5 = vh5;
        vf_x_6 = vh6;
        vf_x_7 = vh7;

        vf_x_0 *= vbeta;
        vf_x_1 *= vbeta;
        vf_x_2 *= vbeta;
        vf_x_3 *= vbeta;
        vf_x_4 *= vbeta;
        vf_x_5 *= vbeta;
        vf_x_6 *= vbeta;
        vf_x_7 *= vbeta;

        vf_dy_0 = vf_dy_0 + vf_x_0;
        vf_dy_1 = vf_dy_1 + vf_x_1;
        vf_dy_2 = vf_dy_2 + vf_x_2;
        vf_dy_3 = vf_dy_3 + vf_x_3;
        vf_dy_4 = vf_dy_4 + vf_x_4;
        vf_dy_5 = vf_dy_5 + vf_x_5;
        vf_dy_6 = vf_dy_6 + vf_x_6;
        vf_dy_7 = vf_dy_7 + vf_x_7;

        vh0 = vf_dy_0;
        vh1 = vf_dy_1;
        vh2 = vf_dy_2;
        vh3 = vf_dy_3;
        vh4 = vf_dy_4;
        vh5 = vf_dy_5;
        vh6 = vf_dy_6;
        vh7 = vf_dy_7;

        simd_store(vh0, dx + i);
        simd_store(vh1, dx + i + 16);
        simd_store(vh2, dx + i + 32);
        simd_store(vh3, dx + i + 48);
        simd_store(vh4, dx + i + 64);
        simd_store(vh5, dx + i + 80);
        simd_store(vh6, dx + i + 96);
        simd_store(vh7, dx + i + 112);
    }
}

// v2: if (fabs(alpha - 1.0f) > 1e-5)
__device__ static void backwardSiluV2(half *dx, half *dy, half *x, half *buf, int num, float alpha,
                                      float beta) {
    float A[128] __attribute__((aligned(64)));
    floatv16 v1 = 1.0f;
    floatv16 valpha = alpha;
    float16v16 vh0, vh1, vh2, vh3, vh4, vh5, vh6, vh7;
    floatv16 vf_dy_0, vf_dy_1, vf_dy_2, vf_dy_3, vf_dy_4, vf_dy_5, vf_dy_6, vf_dy_7;
    floatv16 vf_sg_0, vf_sg_1, vf_sg_2, vf_sg_3, vf_sg_4, vf_sg_5, vf_sg_6, vf_sg_7;
    floatv16 vf_x_0, vf_x_1, vf_x_2, vf_x_3, vf_x_4, vf_x_5, vf_x_6, vf_x_7;
    for (int i = 0; i < num; i += 128) {
        simd_load(vh0, x + i);
        simd_load(vh1, x + i + 16);
        simd_load(vh2, x + i + 32);
        simd_load(vh3, x + i + 48);
        simd_load(vh4, x + i + 64);
        simd_load(vh5, x + i + 80);
        simd_load(vh6, x + i + 96);
        simd_load(vh7, x + i + 112);

        vf_x_0 = vh0;
        vf_x_1 = vh1;
        vf_x_2 = vh2;
        vf_x_3 = vh3;
        vf_x_4 = vh4;
        vf_x_5 = vh5;
        vf_x_6 = vh6;
        vf_x_7 = vh7;

        simd_store(vf_x_0, A);
        simd_store(vf_x_1, A + 16);
        simd_store(vf_x_2, A + 32);
        simd_store(vf_x_3, A + 48);
        simd_store(vf_x_4, A + 64);
        simd_store(vf_x_5, A + 80);
        simd_store(vf_x_6, A + 96);
        simd_store(vf_x_7, A + 112);

        simd_load(vh0, dy + i);
        simd_load(vh1, dy + i + 16);
        simd_load(vh2, dy + i + 32);
        simd_load(vh3, dy + i + 48);
        simd_load(vh4, dy + i + 64);
        simd_load(vh5, dy + i + 80);
        simd_load(vh6, dy + i + 96);
        simd_load(vh7, dy + i + 112);

        simd_sigmoid128(A);  // sigmoid(x)

        vf_dy_0 = vh0;
        vf_dy_1 = vh1;
        vf_dy_2 = vh2;
        vf_dy_3 = vh3;
        vf_dy_4 = vh4;
        vf_dy_5 = vh5;
        vf_dy_6 = vh6;
        vf_dy_7 = vh7;

        simd_load(vf_sg_0, A);
        simd_load(vf_sg_1, A + 16);
        simd_load(vf_sg_2, A + 32);
        simd_load(vf_sg_3, A + 48);
        simd_load(vf_sg_4, A + 64);
        simd_load(vf_sg_5, A + 80);
        simd_load(vf_sg_6, A + 96);
        simd_load(vf_sg_7, A + 112);

        vf_dy_0 = vf_dy_0 * vf_sg_0;
        vf_dy_1 = vf_dy_1 * vf_sg_1;
        vf_dy_2 = vf_dy_2 * vf_sg_2;
        vf_dy_3 = vf_dy_3 * vf_sg_3;
        vf_dy_4 = vf_dy_4 * vf_sg_4;
        vf_dy_5 = vf_dy_5 * vf_sg_5;
        vf_dy_6 = vf_dy_6 * vf_sg_6;
        vf_dy_7 = vf_dy_7 * vf_sg_7;

        vf_sg_0 = v1 - vf_sg_0;
        vf_sg_1 = v1 - vf_sg_1;
        vf_sg_2 = v1 - vf_sg_2;
        vf_sg_3 = v1 - vf_sg_3;
        vf_sg_4 = v1 - vf_sg_4;
        vf_sg_5 = v1 - vf_sg_5;
        vf_sg_6 = v1 - vf_sg_6;
        vf_sg_7 = v1 - vf_sg_7;

        vf_x_0 *= vf_sg_0;
        vf_x_1 *= vf_sg_1;
        vf_x_2 *= vf_sg_2;
        vf_x_3 *= vf_sg_3;
        vf_x_4 *= vf_sg_4;
        vf_x_5 *= vf_sg_5;
        vf_x_6 *= vf_sg_6;
        vf_x_7 *= vf_sg_7;

        vf_x_0 += v1;
        vf_x_1 += v1;
        vf_x_2 += v1;
        vf_x_3 += v1;
        vf_x_4 += v1;
        vf_x_5 += v1;
        vf_x_6 += v1;
        vf_x_7 += v1;

        vf_dy_0 = vf_dy_0 * vf_x_0;
        vf_dy_1 = vf_dy_1 * vf_x_1;
        vf_dy_2 = vf_dy_2 * vf_x_2;
        vf_dy_3 = vf_dy_3 * vf_x_3;
        vf_dy_4 = vf_dy_4 * vf_x_4;
        vf_dy_5 = vf_dy_5 * vf_x_5;
        vf_dy_6 = vf_dy_6 * vf_x_6;
        vf_dy_7 = vf_dy_7 * vf_x_7;

        vf_dy_0 = vf_dy_0 * valpha;
        vf_dy_1 = vf_dy_1 * valpha;
        vf_dy_2 = vf_dy_2 * valpha;
        vf_dy_3 = vf_dy_3 * valpha;
        vf_dy_4 = vf_dy_4 * valpha;
        vf_dy_5 = vf_dy_5 * valpha;
        vf_dy_6 = vf_dy_6 * valpha;
        vf_dy_7 = vf_dy_7 * valpha;

        vh0 = vf_dy_0;
        vh1 = vf_dy_1;
        vh2 = vf_dy_2;
        vh3 = vf_dy_3;
        vh4 = vf_dy_4;
        vh5 = vf_dy_5;
        vh6 = vf_dy_6;
        vh7 = vf_dy_7;

        simd_store(vh0, dx + i);
        simd_store(vh1, dx + i + 16);
        simd_store(vh2, dx + i + 32);
        simd_store(vh3, dx + i + 48);
        simd_store(vh4, dx + i + 64);
        simd_store(vh5, dx + i + 80);
        simd_store(vh6, dx + i + 96);
        simd_store(vh7, dx + i + 112);
    }
}

// v3: if (fabs(beta) > 1e-5)
__device__ static void backwardSiluV3(half *dx, half *dy, half *x, half *buf, int num, float alpha,
                                      float beta) {
    float A[128] __attribute__((aligned(64)));
    floatv16 v1 = 1.0f;
    floatv16 vbeta = beta;
    float16v16 vh0, vh1, vh2, vh3, vh4, vh5, vh6, vh7;
    floatv16 vf_dy_0, vf_dy_1, vf_dy_2, vf_dy_3, vf_dy_4, vf_dy_5, vf_dy_6, vf_dy_7;
    floatv16 vf_sg_0, vf_sg_1, vf_sg_2, vf_sg_3, vf_sg_4, vf_sg_5, vf_sg_6, vf_sg_7;
    floatv16 vf_x_0, vf_x_1, vf_x_2, vf_x_3, vf_x_4, vf_x_5, vf_x_6, vf_x_7;
    for (int i = 0; i < num; i += 128) {
        simd_load(vh0, x + i);
        simd_load(vh1, x + i + 16);
        simd_load(vh2, x + i + 32);
        simd_load(vh3, x + i + 48);
        simd_load(vh4, x + i + 64);
        simd_load(vh5, x + i + 80);
        simd_load(vh6, x + i + 96);
        simd_load(vh7, x + i + 112);

        vf_x_0 = vh0;
        vf_x_1 = vh1;
        vf_x_2 = vh2;
        vf_x_3 = vh3;
        vf_x_4 = vh4;
        vf_x_5 = vh5;
        vf_x_6 = vh6;
        vf_x_7 = vh7;

        simd_store(vf_x_0, A);
        simd_store(vf_x_1, A + 16);
        simd_store(vf_x_2, A + 32);
        simd_store(vf_x_3, A + 48);
        simd_store(vf_x_4, A + 64);
        simd_store(vf_x_5, A + 80);
        simd_store(vf_x_6, A + 96);
        simd_store(vf_x_7, A + 112);

        simd_load(vh0, dy + i);
        simd_load(vh1, dy + i + 16);
        simd_load(vh2, dy + i + 32);
        simd_load(vh3, dy + i + 48);
        simd_load(vh4, dy + i + 64);
        simd_load(vh5, dy + i + 80);
        simd_load(vh6, dy + i + 96);
        simd_load(vh7, dy + i + 112);

        simd_sigmoid128(A);  // sigmoid(x)

        vf_dy_0 = vh0;
        vf_dy_1 = vh1;
        vf_dy_2 = vh2;
        vf_dy_3 = vh3;
        vf_dy_4 = vh4;
        vf_dy_5 = vh5;
        vf_dy_6 = vh6;
        vf_dy_7 = vh7;

        simd_load(vf_sg_0, A);
        simd_load(vf_sg_1, A + 16);
        simd_load(vf_sg_2, A + 32);
        simd_load(vf_sg_3, A + 48);
        simd_load(vf_sg_4, A + 64);
        simd_load(vf_sg_5, A + 80);
        simd_load(vf_sg_6, A + 96);
        simd_load(vf_sg_7, A + 112);

        vf_dy_0 = vf_dy_0 * vf_sg_0;
        vf_dy_1 = vf_dy_1 * vf_sg_1;
        vf_dy_2 = vf_dy_2 * vf_sg_2;
        vf_dy_3 = vf_dy_3 * vf_sg_3;
        vf_dy_4 = vf_dy_4 * vf_sg_4;
        vf_dy_5 = vf_dy_5 * vf_sg_5;
        vf_dy_6 = vf_dy_6 * vf_sg_6;
        vf_dy_7 = vf_dy_7 * vf_sg_7;

        vf_sg_0 = v1 - vf_sg_0;
        vf_sg_1 = v1 - vf_sg_1;
        vf_sg_2 = v1 - vf_sg_2;
        vf_sg_3 = v1 - vf_sg_3;
        vf_sg_4 = v1 - vf_sg_4;
        vf_sg_5 = v1 - vf_sg_5;
        vf_sg_6 = v1 - vf_sg_6;
        vf_sg_7 = v1 - vf_sg_7;

        vf_x_0 *= vf_sg_0;
        vf_x_1 *= vf_sg_1;
        vf_x_2 *= vf_sg_2;
        vf_x_3 *= vf_sg_3;
        vf_x_4 *= vf_sg_4;
        vf_x_5 *= vf_sg_5;
        vf_x_6 *= vf_sg_6;
        vf_x_7 *= vf_sg_7;

        vf_x_0 += v1;
        vf_x_1 += v1;
        vf_x_2 += v1;
        vf_x_3 += v1;
        vf_x_4 += v1;
        vf_x_5 += v1;
        vf_x_6 += v1;
        vf_x_7 += v1;

        vf_dy_0 = vf_dy_0 * vf_x_0;
        vf_dy_1 = vf_dy_1 * vf_x_1;
        vf_dy_2 = vf_dy_2 * vf_x_2;
        vf_dy_3 = vf_dy_3 * vf_x_3;
        vf_dy_4 = vf_dy_4 * vf_x_4;
        vf_dy_5 = vf_dy_5 * vf_x_5;
        vf_dy_6 = vf_dy_6 * vf_x_6;
        vf_dy_7 = vf_dy_7 * vf_x_7;

        simd_load(vh0, dx + i);
        simd_load(vh1, dx + i + 16);
        simd_load(vh2, dx + i + 32);
        simd_load(vh3, dx + i + 48);
        simd_load(vh4, dx + i + 64);
        simd_load(vh5, dx + i + 80);
        simd_load(vh6, dx + i + 96);
        simd_load(vh7, dx + i + 112);

        vf_x_0 = vh0;
        vf_x_1 = vh1;
        vf_x_2 = vh2;
        vf_x_3 = vh3;
        vf_x_4 = vh4;
        vf_x_5 = vh5;
        vf_x_6 = vh6;
        vf_x_7 = vh7;

        vf_x_0 *= vbeta;
        vf_x_1 *= vbeta;
        vf_x_2 *= vbeta;
        vf_x_3 *= vbeta;
        vf_x_4 *= vbeta;
        vf_x_5 *= vbeta;
        vf_x_6 *= vbeta;
        vf_x_7 *= vbeta;

        vf_dy_0 = vf_dy_0 + vf_x_0;
        vf_dy_1 = vf_dy_1 + vf_x_1;
        vf_dy_2 = vf_dy_2 + vf_x_2;
        vf_dy_3 = vf_dy_3 + vf_x_3;
        vf_dy_4 = vf_dy_4 + vf_x_4;
        vf_dy_5 = vf_dy_5 + vf_x_5;
        vf_dy_6 = vf_dy_6 + vf_x_6;
        vf_dy_7 = vf_dy_7 + vf_x_7;

        vh0 = vf_dy_0;
        vh1 = vf_dy_1;
        vh2 = vf_dy_2;
        vh3 = vf_dy_3;
        vh4 = vf_dy_4;
        vh5 = vf_dy_5;
        vh6 = vf_dy_6;
        vh7 = vf_dy_7;

        simd_store(vh0, dx + i);
        simd_store(vh1, dx + i + 16);
        simd_store(vh2, dx + i + 32);
        simd_store(vh3, dx + i + 48);
        simd_store(vh4, dx + i + 64);
        simd_store(vh5, dx + i + 80);
        simd_store(vh6, dx + i + 96);
        simd_store(vh7, dx + i + 112);
    }
}

}  // namespace kernel
}  // namespace ual
}  // namespace tecoal
