// BSD 3- Clause License Copyright (c) 2024, Tecorigin Co., Ltd. All rights
// reserved.
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are met:
// Redistributions of source code must retain the above copyright notice,
// this list of conditions and the following disclaimer.
// Redistributions in binary form must reproduce the above copyright notice,
// this list of conditions and the following disclaimer in the documentation
// and/or other materials provided with the distribution.
// Neither the name of the copyright holder nor the names of its contributors
// may be used to endorse or promote products derived from this software
// without specific prior written permission.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
// ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
// LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
// CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
// SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
// INTERRUPTION)
// HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
// STRICT LIABILITY,OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)  ARISING IN ANY
// WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY
// OF SUCH DAMAGE.

#include "ual/kernel/add_tensor/add_tensor.h"
#include "ual/kernel/macro.h"

using namespace sdaa;
using namespace tecoal::ual::common;

namespace tecoal {
namespace ual {
namespace kernel {

#define MAX(a, b) ((a) >= (b) ? (a) : (b))
#define MIN(a, b) ((a) <= (b) ? (a) : (b))

// double buffer: current addr, another addr, exchange flag
#define CDBUF(x) (x[x##_dbflag])
#define ADBUF(x) (x[1 - x##_dbflag])
#define EXDBF(x) x##_dbflag = 1 - x##_dbflag

typedef _Float16 half;

// DataType : half
// N*H*W*C%2 == 0

__global__ void tecoKernelAddTensorHalfSingleThreadImpl(AddTensorArgs arg) {
    // Get args value
    const int data_num = arg.c_n_num * arg.c_hw_num * arg.a_c_num;
    const float alpha = arg.alpha;
    const float beta = arg.beta;

    // Cast A, C to _Float16 pointer
    _Float16 *A = (_Float16 *)arg.A;
    _Float16 *C = (_Float16 *)arg.C;

    if (threadIdx == 0) {
        for (int i = 0; i < data_num; i++) {
            C[i] = C[i] * beta + A[i] * alpha;
        }
    }
}

__global__ void tecoKernelAddTensorHalfMultiThreadsImpl(AddTensorArgs arg) {
    // Get args value
    const int spe_num = arg.spe_num;
    const int data_num = arg.c_n_num * arg.c_hw_num * arg.a_c_num;
    const float alpha = arg.alpha;
    const float beta = arg.beta;

    // Cast A, C to _Float16 pointer
    _Float16 *A = (_Float16 *)arg.A;
    _Float16 *C = (_Float16 *)arg.C;

    // Calculate the number of elements each core should handle
    size_t per_spe_num = (data_num + spe_num - 1) / spe_num;

    // Calculate the starting index and the ending index for the current thread
    size_t start = threadIdx * per_spe_num;
    const int end = MIN(start + per_spe_num, data_num);

    for (int i = start; i < end; i++) {
        C[i] = C[i] * beta + A[i] * alpha;
    }
}

__global__ void tecoKernelAddTensorHalfDoubleBufferImpl(AddTensorArgs arg) {
    // Get args value
    const int spe_num = arg.spe_num;
    const int data_num = arg.c_n_num * arg.c_hw_num * arg.a_c_num;
    const float alpha = arg.alpha;
    const float beta = arg.beta;

    // Cast A, C to _Float16 pointer
    _Float16 *A = (_Float16 *)arg.A;
    _Float16 *C = (_Float16 *)arg.C;

    // Calculate the number of elements each core should handle
    size_t per_spe_num = (data_num + spe_num - 1) / spe_num;

    // Calculate the starting index and the ending index for the current thread
    size_t start = threadIdx * per_spe_num;
    const int end = MIN(start + per_spe_num, data_num);
    if (end <= start) return;

    // Define the maximum block size for double buffer
    const int MAX_BLK = 56 * 1024;
    const int max_blk = MAX_BLK / sizeof(half);

    // Define double buffer arrays for A, C
    half *a_buf[2];
    half *c_buf[2];

    // Flag for indicating the current buffer for A, C
    int a_buf_dbflag = 0;
    int c_buf_dbflag = 0;

    // Allocate memory for A, C buffer
    a_buf[0] = (half *)malloc(MAX_BLK);
    a_buf[1] = (half *)malloc(MAX_BLK);
    c_buf[0] = (half *)malloc(MAX_BLK);
    c_buf[1] = (half *)malloc(MAX_BLK);

    // Memory copy handles
    MemcpyHandle get_handle[2];
    MemcpyHandle put_handle;

    // Calculate the size of the next block
    int next_blk = MIN(max_blk, end - start);

    // Copy data from global memory to shared memory using double buffering
    memcpy_async(ADBUF(a_buf), A + start, next_blk * sizeof(half), MemcpyGlobalToSpm,
                 get_handle[a_buf_dbflag]);
    memcpy_async(ADBUF(c_buf), C + start, next_blk * sizeof(half), MemcpyGlobalToSpm,
                 get_handle[a_buf_dbflag]);

    for (int i = start; i < end; i += max_blk) {
        const int curr_blk = MIN(max_blk, end - i);
        next_blk = MIN(max_blk, end - i - max_blk);

        // Wait for the current block data to be copied from global memory to shared memory
        memcpy_wait(get_handle[a_buf_dbflag]);
        memcpy_wait(put_handle);

        // Exchange double buffer flags
        EXDBF(a_buf);
        EXDBF(c_buf);

        // Check if there's data for the next block
        if (next_blk > 0) {
            // Copy data for the next block from global memory to shared memory using double
            // buffering
            memcpy_async(ADBUF(a_buf), A + (i + max_blk), next_blk * sizeof(half),
                         MemcpyGlobalToSpm, get_handle[a_buf_dbflag]);
            memcpy_async(ADBUF(c_buf), C + (i + max_blk), next_blk * sizeof(half),
                         MemcpyGlobalToSpm, get_handle[a_buf_dbflag]);
        }

        // Perform tensor addition operation for the current block
        for (int ii = 0; ii < curr_blk; ii += 1) {
            *(CDBUF(c_buf) + ii) = (*(CDBUF(c_buf) + ii)) * beta + (*(CDBUF(a_buf) + ii)) * alpha;
        }

        // Copy the updated data from shared memory back to global memory
        memcpy_async(C + i, CDBUF(c_buf), curr_blk * sizeof(half), MemcpySpmToGlobal, put_handle);
    }

    memcpy_wait(put_handle);

    // Free the allocated memory for double buffer arrays
    free(a_buf[0]);
    free(a_buf[1]);
    free(c_buf[0]);
    free(c_buf[1]);
    return;
}

__global__ void tecoKernelAddTensorHalfSIMDImpl(AddTensorArgs arg) {
    // Get args value
    const int spe_num = arg.spe_num;
    const int data_num = arg.c_n_num * arg.c_hw_num * arg.a_c_num;
    const float alpha = arg.alpha;
    const float beta = arg.beta;

    // Cast A, C to _Float16 pointer
    _Float16 *A = (_Float16 *)arg.A;
    _Float16 *C = (_Float16 *)arg.C;

    // Calculate the number of elements each core should handle
    size_t per_spe_num = (data_num + spe_num - 1) / spe_num;

    // Vectorized variables
    floatv16 v_c_temp;
    float16v16 v_a, v_c;
    float16v16 v_alpha = alpha;
    float16v16 v_beta = beta;

    // Calculate the starting index and the ending index for the current thread
    size_t start = threadIdx * per_spe_num;
    const int end = MIN(start + per_spe_num, data_num);
    if (end <= start) return;

    // Define the maximum block size for double buffer
    const int MAX_BLK = 56 * 1024;
    const int max_blk = MAX_BLK / sizeof(half);

    // Define double buffer arrays for A, C
    half *a_buf[2];
    half *c_buf[2];

    // Flag for indicating the current buffer for A, C
    int a_buf_dbflag = 0;
    int c_buf_dbflag = 0;

    // Allocate memory for A, C buffer
    a_buf[0] = (half *)malloc(MAX_BLK);
    a_buf[1] = (half *)malloc(MAX_BLK);
    c_buf[0] = (half *)malloc(MAX_BLK);
    c_buf[1] = (half *)malloc(MAX_BLK);

    // Memory copy handles
    MemcpyHandle get_handle[2];
    MemcpyHandle put_handle;

    // Calculate the size of the next block
    int next_blk = MIN(max_blk, end - start);

    // Copy data from global memory to shared memory using double buffering
    memcpy_async(ADBUF(a_buf), A + start, next_blk * sizeof(half), MemcpyGlobalToSpm,
                 get_handle[a_buf_dbflag]);
    memcpy_async(ADBUF(c_buf), C + start, next_blk * sizeof(half), MemcpyGlobalToSpm,
                 get_handle[a_buf_dbflag]);

    for (int i = start; i < end; i += max_blk) {
        const int curr_blk = MIN(max_blk, end - i);
        next_blk = MIN(max_blk, end - i - max_blk);

        // Wait for the current block data to be copied from global memory to shared memory
        memcpy_wait(get_handle[a_buf_dbflag]);
        memcpy_wait(put_handle);

        // Exchange double buffer flags
        EXDBF(a_buf);
        EXDBF(c_buf);

        // Check if there's data for the next block
        if (next_blk > 0) {
            // Copy data for the next block from global memory to shared memory using double
            // buffering
            memcpy_async(ADBUF(a_buf), A + (i + max_blk), next_blk * sizeof(half),
                         MemcpyGlobalToSpm, get_handle[a_buf_dbflag]);
            memcpy_async(ADBUF(c_buf), C + (i + max_blk), next_blk * sizeof(half),
                         MemcpyGlobalToSpm, get_handle[a_buf_dbflag]);
        }

        // Perform tensor addition operation for the current block
        for (int ii = 0; ii < curr_blk; ii += 16) {
            simd_load(v_a, CDBUF(a_buf) + ii);
            simd_load(v_c, CDBUF(c_buf) + ii);
            v_c_temp = v_c * v_beta + v_a * v_alpha;
            v_c = simd_cvt_f2h(v_c_temp);
            simd_store(v_c, CDBUF(c_buf) + ii);
        }

        // Copy the updated data from shared memory back to global memory
        memcpy_async(C + i, CDBUF(c_buf), curr_blk * sizeof(half), MemcpySpmToGlobal, put_handle);
    }

    memcpy_wait(put_handle);

    // Free the allocated memory for double buffer arrays
    free(a_buf[0]);
    free(a_buf[1]);
    free(c_buf[0]);
    free(c_buf[1]);
    return;
}

}  // namespace kernel
}  // namespace ual
}  // namespace tecoal