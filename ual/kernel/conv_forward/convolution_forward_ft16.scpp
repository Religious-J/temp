// BSD 3- Clause License Copyright (c) 2024, Tecorigin Co., Ltd. All rights
// reserved.
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are met:
// Redistributions of source code must retain the above copyright notice,
// this list of conditions and the following disclaimer.
// Redistributions in binary form must reproduce the above copyright notice,
// this list of conditions and the following disclaimer in the documentation
// and/or other materials provided with the distribution.
// Neither the name of the copyright holder nor the names of its contributors
// may be used to endorse or promote products derived from this software
// without specific prior written permission.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
// ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
// LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
// CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
// SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
// INTERRUPTION)
// HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
// STRICT LIABILITY,OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)  ARISING IN ANY
// WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY
// OF SUCH DAMAGE.

#include <sdaa_matmul.h>
#include <sdaa_transpose.h>
#include "ual/kernel/conv_forward/conv_forward.h"
#include "ual/kernel/macro.h"

using namespace sdaa;
using namespace tecoal::ual::common;

namespace tecoal {
namespace ual {
namespace kernel {

#define ft16 _Float16

// Calculates the linear index for an element in X, W, Y
#define X(n, h, w, c) ((((n)*H + h) * W + w) * C + c)
#define W(c, r, s, m) ((((c)*R + r) * S + s) * M + m)
#define Y(n, e, f, m) ((((n)*E + e) * F + f) * M + m)

#define bEF 128
#define bC 32
#define bM 32

#define CDBUF(x) (x + (x##_size >> 1) * x##_dbflag)
#define ADBUF(x) (x + (1 - x##_dbflag) * (x##_size >> 1))
#define EXDBF(x) x##_dbflag = 1 - x##_dbflag

template <typename TYPE>
__device__ void tecoKernelConvFwdFT16SingleThreadImpl(ConvFwdArgs arg) {
    const int tid = threadIdx;
    const int N = arg.N;
    const int C = arg.C;
    const int H = arg.H;
    const int W = arg.W;
    const int M = arg.M;
    const int R = arg.R;
    const int S = arg.S;
    const int E = arg.E;
    const int F = arg.F;
    const int PH = arg.pad_h;
    const int PW = arg.pad_w;
    const int SH = arg.stride_h;
    const int SW = arg.stride_w;
    const int DH = arg.dilation_h;
    const int DW = arg.dilation_w;
    const ft16 *x = (const ft16 *)arg.x;
    const ft16 *w = (const ft16 *)arg.w;
    ft16 *y = (ft16 *)arg.y;

    const int DR = (DH - 1) * (R - 1) + R;
    const int DS = (DW - 1) * (S - 1) + S;

    if (tid == 0) {
        for (int n = 0; n < N; ++n) {
            for (int e = 0; e < E; ++e) {
                for (int f = 0; f < F; ++f) {
                    for (int m = 0; m < M; ++m) {
                        float sum = 0.0f;
                        for (int r = 0; r < DR; r += DH) {
                            for (int s = 0; s < DS; s += DW) {
                                int real_h = e * SH + r - PH;
                                int real_w = f * SW + s - PW;
                                if (real_h >= 0 && real_h < H && real_w >= 0 && real_w < W) {
                                    int real_r = r / DH;
                                    int real_s = s / DW;
                                    for (int c = 0; c < C; ++c) {
                                        sum += (float)x[X(n, real_h, real_w, c)] *
                                               (float)w[W(c, real_r, real_s, m)];
                                    }
                                }
                            }
                        }
                        y[Y(n, e, f, m)] = (ft16)sum;
                    }
                }
            }
        }

        return;
    }
}

template <typename TYPE>
__device__ void tecoKernelConvFwdFT16MultiThreadsImpl(ConvFwdArgs arg) {
    const int tid = threadIdx;
    const int N = arg.N;
    const int C = arg.C;
    const int H = arg.H;
    const int W = arg.W;
    const int M = arg.M;
    const int R = arg.R;
    const int S = arg.S;
    const int E = arg.E;
    const int F = arg.F;
    const int PH = arg.pad_h;
    const int PW = arg.pad_w;
    const int SH = arg.stride_h;
    const int SW = arg.stride_w;
    const int DH = arg.dilation_h;
    const int DW = arg.dilation_w;
    const ft16 *x = (const ft16 *)arg.x;
    const ft16 *w = (const ft16 *)arg.w;
    ft16 *y = (ft16 *)arg.y;

    const int DR = (DH - 1) * (R - 1) + R;
    const int DS = (DW - 1) * (S - 1) + S;

    // Convolution loop over batch size (N).
    for (int n = tid; n < N; n += threadDim) {
        for (int e = 0; e < E; ++e) {
            for (int f = 0; f < F; ++f) {
                for (int m = 0; m < M; ++m) {
                    float sum = 0.0f;
                    for (int r = 0; r < DR; r += DH) {
                        for (int s = 0; s < DS; s += DW) {
                            int real_h = e * SH + r - PH;
                            int real_w = f * SW + s - PW;
                            if (real_h >= 0 && real_h < H && real_w >= 0 && real_w < W) {
                                int real_r = r / DH;
                                int real_s = s / DW;
                                for (int c = 0; c < C; ++c) {
                                    sum += (float)x[X(n, real_h, real_w, c)] *
                                           (float)w[W(c, real_r, real_s, m)];
                                }
                            }
                        }
                    }
                    y[Y(n, e, f, m)] = (ft16)sum;
                }
            }
        }
    }

    return;
}

template <typename TYPE>
__device__ void tecoKernelConvFwdFT16DMAImpl(ConvFwdArgs arg) {
    const int tid = threadIdx;
    const int N = arg.N;
    const int C = arg.C;
    const int H = arg.H;
    const int W = arg.W;
    const int M = arg.M;
    const int R = arg.R;
    const int S = arg.S;
    const int E = arg.E;
    const int F = arg.F;
    const int PH = arg.pad_h;
    const int PW = arg.pad_w;
    const int SH = arg.stride_h;
    const int SW = arg.stride_w;
    const int DH = arg.dilation_h;
    const int DW = arg.dilation_w;
    const ft16 *x = (const ft16 *)arg.x;
    const ft16 *w = (const ft16 *)arg.w;
    ft16 *y = (ft16 *)arg.y;

    const int DR = (DH - 1) * (R - 1) + R;
    const int DS = (DW - 1) * (S - 1) + S;

    // Create buffers and allocate memory
    const int x_buf_size = H * W * C * sizeof(ft16);
    const int w_buf_size = C * R * S * M * sizeof(ft16);
    const int y_buf_size = E * F * M * sizeof(ft16);
    ft16 *x_buf = (ft16 *)malloc(x_buf_size);
    ft16 *w_buf = (ft16 *)malloc(w_buf_size);
    ft16 *y_buf = (ft16 *)malloc(y_buf_size);

    // Transfer weights
    memcpy(w_buf, w, w_buf_size);

    // Convolution loop over batch size (N).
    for (int n = tid; n < N; n += threadDim) {
        // Transfer input data
        memcpy(x_buf, x + X(n, 0, 0, 0), x_buf_size);

        for (int e = 0; e < E; ++e) {
            for (int f = 0; f < F; ++f) {
                for (int m = 0; m < M; ++m) {
                    float sum = 0.0f;
                    for (int r = 0; r < DR; r += DH) {
                        for (int s = 0; s < DS; s += DW) {
                            int real_h = e * SH + r - PH;
                            int real_w = f * SW + s - PW;
                            if (real_h >= 0 && real_h < H && real_w >= 0 && real_w < W) {
                                int real_r = r / DH;
                                int real_s = s / DW;
                                for (int c = 0; c < C; ++c) {
                                    sum += (float)x_buf[X(0, real_h, real_w, c)] *
                                           (float)w_buf[W(c, real_r, real_s, m)];
                                }
                            }
                        }
                    }
                    y_buf[Y(0, e, f, m)] = (ft16)sum;
                }
            }
        }

        // Transfer output data
        memcpy(y + Y(n, 0, 0, 0), y_buf, y_buf_size);
    }

    free(x_buf);
    free(w_buf);
    free(y_buf);

    return;
}

template <typename TYPE>
__device__ void tecoKernelConvFwdFT16SIMDImpl(ConvFwdArgs arg) {
    const int tid = threadIdx;
    const int N = arg.N;
    const int C = arg.C;
    const int H = arg.H;
    const int W = arg.W;
    const int M = arg.M;
    const int R = arg.R;
    const int S = arg.S;
    const int E = arg.E;
    const int F = arg.F;
    const int PH = arg.pad_h;
    const int PW = arg.pad_w;
    const int SH = arg.stride_h;
    const int SW = arg.stride_w;
    const int DH = arg.dilation_h;
    const int DW = arg.dilation_w;
    const ft16 *x = (const ft16 *)arg.x;
    const ft16 *w = (const ft16 *)arg.w;
    ft16 *y = (ft16 *)arg.y;

    const int DR = (DH - 1) * (R - 1) + R;
    const int DS = (DW - 1) * (S - 1) + S;

    // Create buffers and allocate memory
    const int x_buf_size = H * W * C * sizeof(ft16);
    const int w_buf_size = C * R * S * M * sizeof(ft16);
    const int y_buf_size = E * F * M * sizeof(ft16);
    ft16 *x_buf = (ft16 *)malloc(x_buf_size);
    ft16 *w_buf = (ft16 *)malloc(w_buf_size);
    ft16 *y_buf = (ft16 *)malloc(y_buf_size);

    // SIMD
    float16v16 v_hx0, v_hx1, v_hw0, v_hw1;
    floatv16 v_fx0, v_fx1, v_fw0, v_fw1;
    floatv16 v_fy0, v_fy1, v_fy;

    // Transfer weights
    transpose(w_buf, w, C, M, sizeof(ft16));

    // Convolution loop over batch size (N).
    for (int n = tid; n < N; n += threadDim) {
        // Transfer input data
        memcpy(x_buf, x + X(n, 0, 0, 0), x_buf_size);

        for (int e = 0; e < E; ++e) {
            for (int f = 0; f < F; ++f) {
                for (int m = 0; m < M; ++m) {
                    v_fy = 0;
                    for (int c = 0; c < C; c += 32) {
                        simd_loadu(v_hx0, x_buf + X(0, e, f, c));
                        simd_loadu(v_hx1, x_buf + X(0, e, f, c + 16));
                        simd_loadu(v_hw0, w_buf + m * C + c);
                        simd_loadu(v_hw1, w_buf + m * C + c + 16);
                        v_fx0 = v_hx0;
                        v_fx1 = v_hx1;
                        v_fw0 = v_hw0;
                        v_fw1 = v_hw1;
                        v_fy0 = v_fx0 * v_fw0;
                        v_fy1 = v_fx1 * v_fw1;
                        v_fy += v_fy0;
                        v_fy += v_fy1;
                    }
                    double sum = 0.0f;
                    for (int i = 0; i < 16; ++i) {
                        sum += (double)v_fy[i];
                    }
                    y_buf[Y(0, e, f, m)] = (ft16)sum;
                }
            }
        }

        // Transfer output data
        memcpy(y + Y(n, 0, 0, 0), y_buf, y_buf_size);
    }

    free(x_buf);
    free(w_buf);
    free(y_buf);

    return;
}

template <typename TYPE>
__device__ void tecoKernelConvFwdFT16MatmulImpl(ConvFwdArgs arg) {
    const int tid = threadIdx;
    const int N = arg.N;
    const int C = arg.C;
    const int H = arg.H;
    const int W = arg.W;
    const int M = arg.M;
    const int R = arg.R;
    const int S = arg.S;
    const int E = arg.E;
    const int F = arg.F;
    const int PH = arg.pad_h;
    const int PW = arg.pad_w;
    const int SH = arg.stride_h;
    const int SW = arg.stride_w;
    const int DH = arg.dilation_h;
    const int DW = arg.dilation_w;
    const ft16 *x = (const ft16 *)arg.x;
    const ft16 *w = (const ft16 *)arg.w;
    ft16 *y = (ft16 *)arg.y;

    const int EF = E * F;

    // Create buffers and allocate memory
    const int x_buf_size = H * W * C * sizeof(ft16);
    const int w_buf_size = C * R * S * M * sizeof(ft16);
    const int y_buf_size = E * F * M * sizeof(ft16);
    ft16 *x_buf = (ft16 *)malloc(x_buf_size);
    ft16 *w_buf = (ft16 *)malloc(w_buf_size);
    ft16 *y_buf = (ft16 *)malloc(y_buf_size);
    ft16 *tmp_buf = (ft16 *)malloc(y_buf_size);

    // Transfer weights
    Stride w_stride(bC, (M - bM) * sizeof(ft16));
    for (int c = 0; c < C; c += bC) {
        for (int m = 0; m < M; m += bM) {
            memcpy_stride(w_buf + c * M + m * bC, w + c * M + m, bM * sizeof(ft16), w_stride);
        }
    }

    // Matmul
    MatmulHandle mma_handle;
    matmul_init(mma_handle, MatmulHalfToHalf);

    // Convolution loop over batch size (N).
    for (int n = tid; n < N; n += threadDim) {
        // Transfer input data
        memcpy(x_buf, x + X(n, 0, 0, 0), x_buf_size);

        // Matmul
        for (int ef = 0; ef < EF; ef += bEF) {
            for (int m = 0; m < M; m += bM) {
                for (int c = 0; c < C; c += bC) {
                    matmul_load_weight(mma_handle, w_buf + c * M + m * bC, MatmulK32, MatmulN32);
                    matmul_wait_loading_weight(mma_handle);
                    matmul_set_flushing_output(mma_handle, c + bC >= C);
                    matmul_compute(mma_handle, x_buf + ef * C + c, bEF, MatmulK32,
                                   C / MatmulK32 - 1);
                    matmul_wait_loading_input(mma_handle);
                }
                matmul_store(mma_handle, y_buf + ef * M + m * bEF, bEF, MatmulN32);
                matmul_wait(mma_handle);
            }
        }

        // Transfer output data
        if (M == 32) {
            memcpy(y + Y(n, 0, 0, 0), y_buf, y_buf_size);
        } else {
            for (int ef = 0; ef < EF; ef += bEF) {
                for (int bef = 0; bef < bEF; ++bef) {
                    for (int m = 0; m < M; m += bM) {
                        memcpy(tmp_buf + ef * M + bef * M + m, y_buf + ef * M + m * bEF + bef * bM,
                               bM * sizeof(ft16));
                    }
                }
            }
            memcpy(y + Y(n, 0, 0, 0), tmp_buf, y_buf_size);
        }
    }

    free(x_buf);
    free(w_buf);
    free(y_buf);
    free(tmp_buf);

    return;
}

template <typename TYPE>
__device__ void tecoKernelConvFwdFT16BroadcastImpl(ConvFwdArgs arg) {
    const int tid = threadIdx;
    const int N = arg.N;
    const int C = arg.C;
    const int H = arg.H;
    const int W = arg.W;
    const int M = arg.M;
    const int R = arg.R;
    const int S = arg.S;
    const int E = arg.E;
    const int F = arg.F;
    const int PH = arg.pad_h;
    const int PW = arg.pad_w;
    const int SH = arg.stride_h;
    const int SW = arg.stride_w;
    const int DH = arg.dilation_h;
    const int DW = arg.dilation_w;
    const ft16 *x = (const ft16 *)arg.x;
    const ft16 *w = (const ft16 *)arg.w;
    ft16 *y = (ft16 *)arg.y;

    const int EF = E * F;

    // Create buffers and allocate memory
    const int x_buf_size = H * W * C * sizeof(ft16);
    const int w_buf_size = C * R * S * M * sizeof(ft16);
    const int y_buf_size = E * F * M * sizeof(ft16);
    ft16 *x_buf = (ft16 *)malloc(x_buf_size);
    ft16 *w_buf = (ft16 *)malloc(w_buf_size);
    ft16 *y_buf = (ft16 *)malloc(y_buf_size);
    ft16 *tmp_buf = (ft16 *)malloc(y_buf_size);

    // Broadcast handle for weight data transfer.
    Stride w_stride(bC, (M - bM) * sizeof(ft16));
    BroadcastHandle w_handle(&w_stride);

    // Transfer weights
    sync_threads();
    for (int c = 0; c < C; c += bC) {
        for (int m = 0; m < M; m += bM) {
            broadcast_async(w_buf + c * M + m * bC, w + c * M + m, bM * sizeof(ft16), 0,
                            BroadcastGlobalToSpm, w_handle);
        }
    }

    // Matmul
    MatmulHandle mma_handle;
    matmul_init(mma_handle, MatmulHalfToHalf);

    // Convolution loop over batch size (N).
    for (int n = tid; n < N; n += threadDim) {
        // Transfer input data
        memcpy(x_buf, x + X(n, 0, 0, 0), x_buf_size);
        if (n == tid) broadcast_wait(w_handle);

        // Matmul
        for (int ef = 0; ef < EF; ef += bEF) {
            for (int m = 0; m < M; m += bM) {
                for (int c = 0; c < C; c += bC) {
                    matmul_load_weight(mma_handle, w_buf + c * M + m * bC, MatmulK32, MatmulN32);
                    matmul_wait_loading_weight(mma_handle);
                    matmul_set_flushing_output(mma_handle, c + bC >= C);
                    matmul_compute(mma_handle, x_buf + ef * C + c, bEF, MatmulK32,
                                   C / MatmulK32 - 1);
                    matmul_wait_loading_input(mma_handle);
                }
                matmul_store(mma_handle, y_buf + ef * M + m * bEF, bEF, MatmulN32);
                matmul_wait(mma_handle);
            }
        }

        // Transfer output data
        if (M == 32) {
            memcpy(y + Y(n, 0, 0, 0), y_buf, y_buf_size);
        } else {
            for (int ef = 0; ef < EF; ef += bEF) {
                for (int bef = 0; bef < bEF; ++bef) {
                    for (int m = 0; m < M; m += bM) {
                        memcpy(tmp_buf + ef * M + bef * M + m, y_buf + ef * M + m * bEF + bef * bM,
                               bM * sizeof(ft16));
                    }
                }
            }
            memcpy(y + Y(n, 0, 0, 0), tmp_buf, y_buf_size);
        }
    }

    free(x_buf);
    free(w_buf);
    free(y_buf);
    free(tmp_buf);

    return;
}

template <typename TYPE>
__device__ void tecoKernelConvFwdFT16DoubleBufferImpl(ConvFwdArgs arg) {
    const int tid = threadIdx;
    const int N = arg.N;
    const int C = arg.C;
    const int H = arg.H;
    const int W = arg.W;
    const int M = arg.M;
    const int R = arg.R;
    const int S = arg.S;
    const int E = arg.E;
    const int F = arg.F;
    const int PH = arg.pad_h;
    const int PW = arg.pad_w;
    const int SH = arg.stride_h;
    const int SW = arg.stride_w;
    const int DH = arg.dilation_h;
    const int DW = arg.dilation_w;
    const ft16 *x = (const ft16 *)arg.x;
    const ft16 *w = (const ft16 *)arg.w;
    ft16 *y = (ft16 *)arg.y;

    const int EF = E * F;

    // Create buffers for temporary storage
    const int x_buf_size = H * W * C * sizeof(ft16);
    const int w_buf_size = C * R * S * M * sizeof(ft16);
    const int y_buf_size = E * F * M * sizeof(ft16);

    // Allocate memory for double buffer
    ft16 *x_buf = (ft16 *)malloc(x_buf_size * 2);
    ft16 *w_buf = (ft16 *)malloc(w_buf_size);
    ft16 *y_buf = (ft16 *)malloc(y_buf_size);
    ft16 *tmp_buf = (ft16 *)malloc(y_buf_size);

    // Double buffering flag for input buffer.
    int x_buf_dbflag = 0;

    // DMA handles for input data transfer.
    MemcpyHandle x_handle[2];

    // Broadcast handle for weight data transfer.
    Stride w_stride(bC, (M - bM) * sizeof(ft16));
    BroadcastHandle w_handle(&w_stride);

    // Transfer input data to buffer1 asynchronously.
    memcpy_async(CDBUF(x_buf), x + X(tid, 0, 0, 0), x_buf_size, MemcpyGlobalToSpm,
                 x_handle[x_buf_dbflag]);

    // Transfer weights using broadcast.
    sync_threads();
    for (int c = 0; c < C; c += bC) {
        for (int m = 0; m < M; m += bM) {
            broadcast_async(w_buf + c * M + m * bC, w + c * M + m, bM * sizeof(ft16), 0,
                            BroadcastGlobalToSpm, w_handle);
        }
    }

    // Initialize Matmul handle
    MatmulHandle mma_handle;
    matmul_init(mma_handle, MatmulHalfToHalf);

    // Convolution loop over batch size (N).
    for (int n = tid; n < N; n += threadDim) {
        if (n + threadDim < N) {
            // Asynchronously transfer next slice of input data to buffer2.
            memcpy_async(ADBUF(x_buf), x + X(n + threadDim, 0, 0, 0), x_buf_size, MemcpyGlobalToSpm,
                         x_handle[1 - x_buf_dbflag]);
        }

        // Wait for weight broadcast to complete.
        if (n == tid) broadcast_wait(w_handle);

        // Wait for input data transfer to buffer.
        memcpy_wait(x_handle[x_buf_dbflag]);

        // Matmul computation.
        for (int ef = 0; ef < EF; ef += bEF) {
            for (int m = 0; m < M; m += bM) {
                for (int c = 0; c < C; c += bC) {
                    // Load weight for matmul.
                    matmul_load_weight(mma_handle, w_buf + c * M + m * bC, MatmulK32, MatmulN32);
                    // Wait for weight loading to complete.
                    matmul_wait_loading_weight(mma_handle);
                    // Set flag for output flushing.
                    matmul_set_flushing_output(mma_handle, c + bC >= C);
                    // Compute matmul.
                    matmul_compute(mma_handle, CDBUF(x_buf) + ef * C + c, bEF, MatmulK32,
                                   C / MatmulK32 - 1);
                    // Wait for input loading to complete.
                    matmul_wait_loading_input(mma_handle);
                }
                // Store matmul result.
                matmul_store(mma_handle, y_buf + ef * M + m * bEF, bEF, MatmulN32);
                // Wait for matmul to complete.
                matmul_wait(mma_handle);
            }
        }

        // Transfer output data back to main memory.
        if (M == 32) {
            // Transfer directly if M is 32.
            memcpy(y + Y(n, 0, 0, 0), y_buf, y_buf_size);
        } else {
            // Transpose and transfer output data if M is not 32.
            for (int ef = 0; ef < EF; ef += bEF) {
                for (int bef = 0; bef < bEF; ++bef) {
                    for (int m = 0; m < M; m += bM) {
                        memcpy(tmp_buf + ef * M + bef * M + m, y_buf + ef * M + m * bEF + bef * bM,
                               bM * sizeof(ft16));
                    }
                }
            }
            // Transfer transposed data.
            memcpy(y + Y(n, 0, 0, 0), tmp_buf, y_buf_size);
        }
        // Exchange double buffering flag for input buffer.
        EXDBF(x_buf);
    }

    free(x_buf);
    free(w_buf);
    free(y_buf);
    free(tmp_buf);

    return;
}

__global__ void tecoKernelConvFwdFT16SingleThread(ConvFwdArgs arg) {
    const UALDataType out_type = arg.out_data_type;
    if (out_type == UALDataType::UAL_DTYPE_HALF) {
        tecoKernelConvFwdFT16SingleThreadImpl<_Float16>(arg);
    }
}

__global__ void tecoKernelConvFwdFT16MultiThreads(ConvFwdArgs arg) {
    const UALDataType out_type = arg.out_data_type;
    if (out_type == UALDataType::UAL_DTYPE_HALF) {
        tecoKernelConvFwdFT16MultiThreadsImpl<_Float16>(arg);
    }
}

__global__ void tecoKernelConvFwdFT16DMA(ConvFwdArgs arg) {
    const UALDataType out_type = arg.out_data_type;
    if (out_type == UALDataType::UAL_DTYPE_HALF) {
        tecoKernelConvFwdFT16DMAImpl<_Float16>(arg);
    }
}

__global__ void tecoKernelConvFwdFT16SIMD(ConvFwdArgs arg) {
    const UALDataType out_type = arg.out_data_type;
    if (out_type == UALDataType::UAL_DTYPE_HALF) {
        tecoKernelConvFwdFT16SIMDImpl<_Float16>(arg);
    }
}

__global__ void tecoKernelConvFwdFT16Matmul(ConvFwdArgs arg) {
    const UALDataType out_type = arg.out_data_type;
    if (out_type == UALDataType::UAL_DTYPE_HALF) {
        tecoKernelConvFwdFT16MatmulImpl<_Float16>(arg);
    }
}

__global__ void tecoKernelConvFwdFT16Broadcast(ConvFwdArgs arg) {
    const UALDataType out_type = arg.out_data_type;
    if (out_type == UALDataType::UAL_DTYPE_HALF) {
        tecoKernelConvFwdFT16BroadcastImpl<_Float16>(arg);
    }
}

__global__ void tecoKernelConvFwdFT16DoubleBuffer(ConvFwdArgs arg) {
    const UALDataType out_type = arg.out_data_type;
    if (out_type == UALDataType::UAL_DTYPE_HALF) {
        tecoKernelConvFwdFT16DoubleBufferImpl<_Float16>(arg);
    }
}

}  // namespace kernel
}  // namespace ual
}  // namespace tecoal