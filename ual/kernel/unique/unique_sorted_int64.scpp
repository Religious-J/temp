// BSD 3- Clause License Copyright (c) 2024, Tecorigin Co., Ltd. All rights
// reserved.
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are met:
// Redistributions of source code must retain the above copyright notice,
// this list of conditions and the following disclaimer.
// Redistributions in binary form must reproduce the above copyright notice,
// this list of conditions and the following disclaimer in the documentation
// and/or other materials provided with the distribution.
// Neither the name of the copyright holder nor the names of its contributors
// may be used to endorse or promote products derived from this software
// without specific prior written permission.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
// ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
// LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
// CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
// SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
// INTERRUPTION)
// HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
// STRICT LIABILITY,OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)  ARISING IN ANY
// WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY
// OF SUCH DAMAGE.

#include "ual/kernel/unique/unique.h"

using namespace sdaa;
using namespace tecoal::ual::common;

namespace tecoal {
namespace ual {
namespace kernel {

#define MAX(a, b) ((a) >= (b) ? (a) : (b))
#define MIN(a, b) ((a) <= (b) ? (a) : (b))

__device__ static int len_spe[32] = {0};
__device__ static int64_t remote_sum_value[96] = {0};

// sort
__device__ static void swap(int le, int ri, int64_t *value, int64_t *index) {
    int64_t t_value = value[le];
    value[le] = value[ri];
    value[ri] = t_value;

    int64_t t_index = index[le];
    index[le] = index[ri];
    index[ri] = t_index;
}

__device__ static void quick_sort(int le, int ri, int64_t *value, int64_t *index) {
    if (le + 1 >= ri) return;
    int mid = le + (ri - le) / 2;
    swap(mid, le, value, index);
    int bound = le;
    for (int i = le + 1; i < ri; ++i) {
        if ((value[i] < value[le]) || ((value[i] == value[le]) && (index[i] < index[le]))) {
            swap(++bound, i, value, index);
        }
    }
    swap(le, bound, value, index);
    quick_sort(le, bound, value, index);
    quick_sort(bound + 1, ri, value, index);
}

// the number of stages required to obtain parity sorting
__device__ static int get_phase_num(int data_len, int spe_num) {
    int Block = (data_len + (spe_num - 1)) / spe_num;
    int phase = 0;
    if (Block > 1) {
        phase = spe_num;
    } else {
        phase = data_len;
    }
    return phase;
}

// obtain parity sorting at a certain stage, a communication partner from the spe
__device__ static int get_partner(int tid, int phase) {
    // In the even communication stage,even numbers refer to the smaller number of
    // communication parties from the kernel.
    if (phase % 2 == 0) {
        if (tid % 2 == 0) {
            return tid + 1;
        } else {
            return tid - 1;
        }
    } else {  // odd communication stage, odd numbers refer to the smaller number.
        if (tid % 2 == 0) {
            return tid - 1;
        } else {
            return tid + 1;
        }
    }
}

__global__ void tecoKernelUniqueSortedInt64(UniqueArgs uniquearg) {
    int spe_num = uniquearg.spe_num;
    unsigned sorted = uniquearg.sorted;
    unsigned return_inverse = uniquearg.return_inverse;
    unsigned return_counts = uniquearg.return_counts;
    int64_t *x = (int64_t *)uniquearg.x;
    int64_t *out_data = (int64_t *)uniquearg.y;
    int64_t *inverse = (int64_t *)uniquearg.inverse;
    int64_t *counts = (int64_t *)uniquearg.counts;
    int64_t *out_size = (int64_t *)uniquearg.out_size;
    int data_len = uniquearg.data_len;
    int tid = threadIdx;
    ThreadGroup thread_group(0xFFFFFFFE);
    BroadcastHandle bcast_handle(&thread_group);

    int data_block = (data_len + (spe_num - 1)) / spe_num;
    int spe_num_r = 0;
    for (int i = 0; i < 32; i++) {
        if (data_block * (i + 1) >= data_len) {
            spe_num_r = i + 1;
            break;
        }
    }
    int ls = MIN(data_len, data_block * tid);
    int re = MIN(data_len, ls + data_block);
    int Block_num = re - ls;
    len_spe[tid] = Block_num;  // 每个核实际处理的框数目
    int alloc_value_size = sizeof(int64_t) * data_block;
    int alloc_index_size = sizeof(int64_t) * data_block;
    int real_value_size = sizeof(int64_t) * Block_num;
    int real_index_size = sizeof(int64_t) * Block_num;
    int64_t *offset = (int64_t *)malloc(32 * sizeof(int64_t));
    int64_t *remote_sum_value_1 = (int64_t *)malloc(32 * sizeof(int64_t));
    int64_t *A_value_buf = (int64_t *)malloc(alloc_value_size);
    int64_t *C_value_buf = (int64_t *)malloc(alloc_value_size);
    int64_t *A_index_buf = (int64_t *)malloc(alloc_index_size);
    int64_t *C_index_buf = (int64_t *)malloc(alloc_index_size);
    int64_t *Merge_value = (int64_t *)malloc(alloc_value_size * 2);
    int64_t *Merge_index = (int64_t *)malloc(alloc_index_size * 2);

    memcpy_async(A_value_buf, x + ls, alloc_value_size, MemcpyGlobalToSpm);
    memcpy_wait();

    for (int64_t i = 0; i < Block_num; i++) {
        A_index_buf[i] = ls + i;
    }

    // Sort the data for each spe first
    quick_sort(0, Block_num, A_value_buf, A_index_buf);
    int phase = get_phase_num(data_len, spe_num);

    RmaHandle remote_reply_index;
    RmaHandle remote_reply_value;

    // Parallel parity sorting, sorting data from spes
    for (int i = 0; i < phase; i++) {
        sync_threads();
        int partner = get_partner(tid, i);
        rma_set_thread_id(remote_reply_index, partner);
        rma_set_thread_id(remote_reply_value, partner);

        if ((i % 2) ^ (tid % 2)) {
            if (tid != 0) {
                rma_wait(remote_reply_index, 1);
                rma_wait(remote_reply_value, 1);
                int C_index_buf_num = len_spe[partner];
                int A_index_buf_num = Block_num;

                for (int j = 0, k = 0, pos = 0; (k < C_index_buf_num) || (j < A_index_buf_num);
                     pos++) {
                    if (k >= C_index_buf_num ||
                        j < A_index_buf_num &&
                            (C_value_buf[k] > A_value_buf[j] ||
                             C_value_buf[k] == A_value_buf[j] && C_index_buf[k] < A_index_buf[j])) {
                        Merge_value[pos] = A_value_buf[j];
                        Merge_index[pos] = A_index_buf[j];
                        ++j;
                    } else {
                        Merge_value[pos] = C_value_buf[k];
                        Merge_index[pos] = C_index_buf[k];
                        ++k;
                    }
                }
                memcpy(A_index_buf, Merge_index + C_index_buf_num, real_index_size);
                memcpy(A_value_buf, Merge_value + C_index_buf_num, real_value_size);

                rma_async_put(Merge_index, A_index_buf, alloc_index_size, remote_reply_index);
                rma_async_put(Merge_value, A_value_buf, alloc_value_size, remote_reply_value);
                rma_complete(remote_reply_index, RmaCustomizeMode);
                rma_complete(remote_reply_value, RmaCustomizeMode);
            }
        } else {
            if (tid != (spe_num - 1)) {
                rma_async_put(A_index_buf, C_index_buf, alloc_index_size, remote_reply_index);
                rma_async_put(A_value_buf, C_value_buf, alloc_value_size, remote_reply_value);
                rma_complete(remote_reply_index, RmaCustomizeMode);
                rma_complete(remote_reply_value, RmaCustomizeMode);
                rma_wait(remote_reply_index, 1);
                rma_wait(remote_reply_value, 1);
            }
        }
    }

    int len_num = Block_num;
    remote_sum_value[tid] = A_value_buf[len_num - 1];
    sync_threads();
    int64_t *output = (int64_t *)C_value_buf;
    int64_t *counts_buf = (int64_t *)C_index_buf;
    int64_t *counts_buf_1 = (int64_t *)Merge_value;
    int64_t *mask = (int64_t *)Merge_index;
    int64_t num_count = 0;
    if (tid == 0) {
        mask[0] = 1;
        num_count++;
    } else {
        if (A_value_buf[0] == remote_sum_value[tid - 1]) {
            mask[0] = 0;
        } else {
            mask[0] = 1;
            num_count++;
        }
    }
    for (int t = 0; t < len_num - 1; t++) {
        if (A_value_buf[t + 1] == A_value_buf[t]) {
            mask[t + 1] = 0;
        } else {
            mask[t + 1] = 1;
            num_count++;
        }
    }
    remote_sum_value[tid + 32] = num_count;
    sync_threads();
    int64_t sum = 0;
    if (tid == 0) {
        offset[0] = 0;
        for (int j = 1; j < spe_num_r; j++) {
            offset[j] = offset[j - 1] + remote_sum_value[j - 1 + 32];
        }
        broadcast_async(offset, offset, 32 * sizeof(int64_t), BroadcastSpmToSpm, bcast_handle);
    }
    if (tid != 0) {
        broadcast_wait(bcast_handle, 1);
    }
    sync_threads();
    int64_t offset_spe = offset[tid];
    int64_t out_of = 0;
    for (int64_t i = 0; i < len_num; i++) {
        if (mask[i]) {
            output[out_of] = A_value_buf[i];
            if (return_counts) {
                counts_buf[out_of] = i + tid * data_block;
            }
            out_of++;
            offset_spe++;
        }
        if (return_inverse == 1) {
            int64_t inverse_index = offset_spe - 1;
            int64_t reorder = A_index_buf[i];
            inverse[reorder] = inverse_index;
        }
    }
    sync_threads();
    if (tid == 0) {
        int64_t finnal_count = remote_sum_value[spe_num_r - 1 + 32];
        int64_t finnal_offset = offset[spe_num_r - 1];
        *out_size = finnal_offset + finnal_count;
    }
    if (return_counts) {
        if (num_count != 0) {
            remote_sum_value[tid + 64] = counts_buf[num_count - 1];
        } else {
            remote_sum_value[tid + 64] = -1;
        }
        sync_threads();
    }
    int64_t offset_out = offset[tid];
    if (num_count != 0 && tid < spe_num_r) {
        memcpy_async(out_data + offset_out, output, num_count * sizeof(int64_t), MemcpySpmToGlobal);
        memcpy_wait();
    }

    if (return_counts == 1) {
        memcpy(remote_sum_value_1, remote_sum_value + 64, 32 * 8);
        if (tid == 0 && num_count > 1) {
            for (int i = 0; i < (num_count - 1); i++) {
                counts_buf_1[i] = counts_buf[i + 1] - counts_buf[i];
            }
            memcpy_async(counts, counts_buf_1, (num_count - 1) * sizeof(int64_t),
                         MemcpySpmToGlobal);
            memcpy_wait();
        } else if (tid != 0 && tid < spe_num_r - 1 && num_count > 0) {
            int len_spe_b = len_spe[tid - 1];
            int64_t before = remote_sum_value_1[tid - 1];
            int64_t r_tid = tid - 1;
            while (before == -1) {
                r_tid = r_tid - 1;
                before = remote_sum_value_1[r_tid];
            }
            for (int i = 1; i < (num_count); i++) {
                counts_buf_1[i] = counts_buf[i] - counts_buf[i - 1];
            }

            counts_buf_1[0] = counts_buf[0] - before;
            memcpy_async(counts + offset[tid] - 1, counts_buf_1, (num_count) * sizeof(int64_t),
                         MemcpySpmToGlobal);
            memcpy_wait();
        } else if (tid == spe_num_r - 1) {
            int len_spe_b = len_spe[tid - 1];
            int64_t before = remote_sum_value_1[tid - 1];
            int64_t r_tid = tid - 1;
            while (before == -1) {
                r_tid = r_tid - 1;
                before = remote_sum_value_1[r_tid];
            }
            if (num_count > 0) {
                counts_buf_1[0] = counts_buf[0] - before;
                counts_buf_1[num_count] = Block_num + tid * data_block - counts_buf[num_count - 1];
                for (int i = 1; i < (num_count); i++) {
                    counts_buf_1[i] = counts_buf[i] - counts_buf[i - 1];
                }
            } else {
                counts_buf_1[0] = data_len - before;
            }
            memcpy_async(counts + offset[tid] - 1, counts_buf_1, (num_count + 1) * sizeof(int64_t),
                         MemcpySpmToGlobal);
            memcpy_wait();
        }
    }
    free(remote_sum_value_1);
    free(A_value_buf);
    free(C_value_buf);
    free(A_index_buf);
    free(C_index_buf);
    free(Merge_value);
    free(Merge_index);
    free(offset);
}

}  // namespace kernel
}  // namespace ual
}  // namespace tecoal